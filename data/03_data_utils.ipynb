{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Backend__\n",
    "\n",
    "* `spark`\n",
    "* `pandas`\n",
    "* `dask`\n",
    "* `ray`\n",
    "\n",
    "__Model Backends__\n",
    "\n",
    "* `sklearn`\n",
    "* `sklearnex`\n",
    "* `xgboost`\n",
    "* `lightgbm`\n",
    "* `catboost`\n",
    "* `pytorch`\n",
    "* `tensorflow`\n",
    "* `SparkML`\n",
    "\n",
    "__Data Format__\n",
    "\n",
    "* `csv`\n",
    "* `parquet`\n",
    "\n",
    "__Compute Backends__\n",
    "\n",
    "* `joblib + dask`\n",
    "* `joblib + ray`\n",
    "* `joblib + ipp`\n",
    "* `joblib + loky`\n",
    "* `joblib + multiprocessing`\n",
    "* `joblib + threading`\n",
    "* `joblib + spark`\n",
    "\n",
    "\n",
    "__Data Store__\n",
    "\n",
    "* `dvc`\n",
    "* `blob`\n",
    "* `local`\n",
    "\n",
    "__Configs__\n",
    "\n",
    "* `data_config.json`\n",
    "* `model_config.json`\n",
    "* `log_config.json`\n",
    "* `config.json`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Env creation to execute ray, dask, spark, modin__\n",
    "\n",
    "```bash\n",
    "conda create -n aikit-modin python=3.8 intel-aikit-modin -c intel -c conda-forge -y\n",
    "conda activate aikit-modin\n",
    "conda install scikit-learn-intelex -c conda-forge\n",
    "pip install ipyparallel joblib jupyter notebook scikit-learn pandas numpy \"dask[distributed]\" watermark joblibspark pyspark tune-sklearn typer \"modin[all]\"\n",
    "pip list --format=freeze > requirements_intel.txt\n",
    "conda deactivate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ray\n",
    "# ray.init(runtime_env={'env_vars': {'__MODIN_AUTOIMPORT_PANDAS__': '1'}})\n",
    "# import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "# from pyspark.sql import SparkSession\n",
    "# import pyspark.pandas as pd\n",
    "# pd.set_option('compute.default_index_type', 'distributed')\n",
    "# spark = SparkSession.builder.master('local[*]').config(\"spark.driver.memory\", \"10g\").getOrCreate()\n",
    "\n",
    "# https://docs.databricks.com/machine-learning/ray-integration.html\n",
    "# https://www.intel.com/content/www/us/en/developer/tools/oneapi/distribution-of-modin.html#gs.qt8guf\n",
    "# https://www.ray.io/ray-datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `DataIO`: This class will have all the methods to read/write data from/to different data stores. It will also have methods to read/write config files. It will also have methods to read/write models. Along with this if there is any other helper utility method that is required to read/write data, it should be added to this class.\n",
    "\n",
    "* `DataParser`: This class will have all the methods to parse the data. For example, if the data type is `number` then it should convert the data type to `int` or `float` based on the data. It should also have methods to parse the date columns with the given date format. Also, wherever possible optimize data to be better suited in memory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import DataParser, MetaDataExtractor, DataProcessor, DataValidator, DataLogger, DataIO, DataProfiler, DataVisualizer\n",
    "\n",
    "# Data Input and Output\n",
    "DataIO.read_data()\n",
    "DataIO.write_data()\n",
    "DataIO.read_config()\n",
    "DataIO.write_config()\n",
    "DataIO.read_config()\n",
    "DataIO.write_config()\n",
    "DataIO.upload_file()\n",
    "DataIO.download_file()\n",
    "\n",
    "# Data Parser\n",
    "DataParser.optimize_data_types()\n",
    "DataParser.parse_date()\n",
    "\n",
    "# Meta Data Extractor\n",
    "MetaDataExtractor.get_counts()\n",
    "MetaDataExtractor.get_date_frequency()\n",
    "MetaDataExtractor.get_data_types()\n",
    "MetaDataExtractor.get_date_format()\n",
    "MetaDataExtractor.get_unique_values()\n",
    "MetaDataExtractor.get_min_max_values()\n",
    "MetaDataExtractor.get_min_max_date()\n",
    "\n",
    "# Data Processor + Any other custom functions for aggregation and stuff\n",
    "DataProcessor.filter_by_range()\n",
    "DataProcessor.filter_by_values()\n",
    "DataProcessor.apply_imputation()\n",
    "\n",
    "\n",
    "# Resampling of data by date and change in date of month, week etc.\n",
    "\n",
    "# Data Validator\n",
    "DataValidator.check_columns()\n",
    "DataValidator.check_duplicates()\n",
    "DataValidator.check_nan()\n",
    "DataValidator.check_min_max()\n",
    "DataValidator.check_min_max_date()\n",
    "DataValidator.check_unique_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIO:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def read_data():\n",
    "        pass\n",
    "    def write_data():\n",
    "        pass\n",
    "    def read_config():\n",
    "        pass\n",
    "    def write_config():\n",
    "        pass\n",
    "    def save_model():\n",
    "        pass\n",
    "    def load_model():\n",
    "        pass\n",
    "    def upload_file():\n",
    "        pass\n",
    "    def download_file():\n",
    "        pass\n",
    "\n",
    "class DataParser:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def optimize_data_types():\n",
    "        pass\n",
    "    def parse_date():\n",
    "        pass\n",
    "\n",
    "class MetaDataExtractor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def get_unique_values():\n",
    "        pass\n",
    "    def get_min_max_values():\n",
    "        pass\n",
    "    def get_min_max_date():\n",
    "        pass\n",
    "    def get_counts():\n",
    "        pass\n",
    "    def get_date_frequency():\n",
    "        pass\n",
    "    def get_data_types():\n",
    "        pass\n",
    "    def get_date_format():\n",
    "        pass\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def rename_columns():\n",
    "        pass\n",
    "    def filter_by_range():\n",
    "        pass\n",
    "    def filter_by_values():\n",
    "        pass\n",
    "    def apply_imputation():\n",
    "        pass\n",
    "\n",
    "class DataValidator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def check_duplicates():\n",
    "        pass\n",
    "    def check_columns():\n",
    "        pass\n",
    "    def check_nan():\n",
    "        pass\n",
    "    def check_min_max():\n",
    "        pass\n",
    "    def check_min_max_date():\n",
    "        pass\n",
    "    def check_unique_values():\n",
    "        pass\n",
    "\n",
    "class DataLogger:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def upload_log():\n",
    "        pass\n",
    "    def download_log():\n",
    "        pass\n",
    "    def read_log():\n",
    "        pass\n",
    "    def write_log():\n",
    "        pass\n",
    "    def log_metadata():\n",
    "        pass\n",
    "    def log_validation():\n",
    "        pass\n",
    "    def log_config():\n",
    "        pass\n",
    "\n",
    "class DataProfiler:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def profile_data():\n",
    "        pass\n",
    "\n",
    "class DataVisualizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def visualize_data():\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aikit-modin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8121b32d35b4abb4d750b8479b72692fa79b5889dc196d3d95aac47162b231e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
